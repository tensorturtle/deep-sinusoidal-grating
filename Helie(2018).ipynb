{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2405089a-24bb-4c78-bc25-dd7fb63bc24f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Notes from \"Can categorical knowledge be used in visual search?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac6b550-c582-4ee5-a75c-70294dca86ce",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "+ Talk about referred papers positively (excellent work on, insightful study...)\n",
    "+ Show deep learning equations\n",
    "+ Refer to lots of papers\n",
    "+ Give things names (new name = new thing)\n",
    "+ Re-analyize the experiments in papers, explaining any unexplained discrepancies with this new lens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1fc815-5926-465a-81ea-04515ba96c99",
   "metadata": {},
   "source": [
    "Story: I have developed patent-pending AI vision systems using deep neural networks. Based on insights gained from implementing synthetic object detection systems that match or exceed human cognition, I feel that I have something to contribute to the discourse about natural human visual facilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c48ff-7d96-4584-a757-daed7d8a1cbe",
   "metadata": {},
   "source": [
    "Fun fact: I was probably one of the `Fifty-eight undergraduate students at Purdue University` who `were recruited to participate in Experiment 2`. or 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df3b57-6889-41a9-89cc-fd5e2b3eefaa",
   "metadata": {},
   "source": [
    "Abstract\n",
    "\n",
    "```\n",
    "However, Smith et al. only studied one kind of category structure.\n",
    "This article presents the results of three experiments exploring the effect of display size on perceptual cate-\n",
    "gorization as a function of category structure. We show that rule-based and information-integration categories\n",
    "are differently affected by display size in the visual search categorization task. \n",
    "```\n",
    "\n",
    "I think this paper heads in the right direction, but does not go nearly far enough to reap the benefits of added parameterization and complexity of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12379417-9f66-404a-a97b-33eb334c7ecc",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "\n",
    "`Categorization reduces the complexity of the environment.`\n",
    "\n",
    "'Complexity' being the key word here.\n",
    "\n",
    "We are assuming a high level of complexity for categorization to work. Generating synthetic environments/tasks that do not have *sufficient* complexity might be problematic.\n",
    "\n",
    "The complexity expands greatly before it gets reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd7b137-c00a-4eea-b141-181a5d032911",
   "metadata": {},
   "source": [
    "1.1 Visual search and categorization\n",
    "\n",
    "```\n",
    "the VSC task allows for studying how participants can parse a relatively complex scene in order to achieve a categorization decision\n",
    "```\n",
    "\n",
    "Is it complex enough? Perhaps not.\n",
    "\n",
    "Proposed reasons for counterintuitive results\n",
    "\n",
    "+ `Category representations learned during the category training portion of the VSC task were not sufficient to support visual search. Categorization and visual search are two different tasks, and Helie and colleagues have shown that ths structures of the learned categories affct the generality and transferability of the category representations.`\n",
    "\n",
    "`Helie and Ashby argued that learning different category structures leads to different kinds of category representations, and that different category representations allow for different generalizability and transfer performance`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98606a29-1490-48a8-a83b-42b341bbccec",
   "metadata": {},
   "source": [
    "Smith(2015)'s dot-distortion task is probablly a informaiton integration task. With sinusoidal gratings, it appears that people are better at generalizing / recalling rule-based schemes than information integration schemes.\n",
    "\n",
    "Had Smith(2015) tried using a rule-based dot-distortion, he might have had more success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523bbb7-2ea1-4d59-b005-965a751a697c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment 1: \n",
    "\n",
    "We know that training II on a YES/NO training condition works poorly.\n",
    "\n",
    "\"Can people transfer knowledge when shifting from a A/B training condition to a YES/NO test condition?\"\n",
    "\n",
    "+ CrossEntropyLoss ANN training closely resembles A/B training, and\n",
    "+ Binary classification task also closely resembles YES/NO test condition.\n",
    "\n",
    "I must establish sufficient similarlity between the human participant study and my in-silico simulations. (see Experiment 1 comparisons)\n",
    "\n",
    "`Accuracy in the last training block of classification was compared with accuracy in the YES/NO transfer block`:\n",
    "\n",
    "+ Training loss was compared with test accuracy\n",
    "\n",
    "This test was performed to see if the change in decisional process (A/B -> YES/NO) could have had an impact in Smith(2005)'s counterintuitive findings.\n",
    "\n",
    "`Experiment 1 shows perfect transfer accuracy from A/B training to the YES/NO categorization paradigms with both RB and II category structures. Hence, this possible change in decisional process cannot account for Smith et al.'s results in the VSC task`\n",
    "\n",
    "#### Procedure\n",
    "6 blocks of 100 trials. = 600\n",
    "\n",
    "500 training A/B, 100 YES/NO test (last block)\n",
    "\n",
    "#### Results\n",
    "\n",
    "Performance increased with training.\n",
    "\n",
    "`There was no evidence of a transfer cost when changing from an A/B categorization task to a YES/NO task after category training had already occured.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe079ca-69f1-439a-9722-9582222643c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment 2\n",
    "\n",
    "`Experiment 2 directly addressed the main goal of the research: Is performance in the VSC task affected by category structures?`\n",
    "\n",
    "`Obtaining a similar collapse in VSC accuracy in both conditions would suggest a general effect of the VSC task, whereas differential change sin performance for each dondition would suggest that category structures modulate performance in the VSC task`\n",
    "\n",
    "Participants did better in RB than II when display size was made fewer.\n",
    "\n",
    "+ Display size was not varied in my experiments\n",
    "\n",
    "#### Procedure\n",
    "\n",
    "Group of 46 split into two, RB and II.\n",
    "\n",
    "Two sessions scheduled in the same week\n",
    "\n",
    "First session: 6 x 100 A/B training\n",
    "Second session: \n",
    "1. Trained for 1x100 traisl in A/B (refresher of session 1)\n",
    "2. Trained for 6x80 in visual search task (1~4 gratings displayed; Is there a \"b\"? - YES/NO)\n",
    "\n",
    "In the VSC training, feedback is given\n",
    "\n",
    "##### Results\n",
    "Accuracy did improve in categorization phase (Is this a A/B?)\n",
    "Accuracy did not improve in visual search phase (Is there a A? among many)\n",
    "\n",
    "Number of simultaneously shown distractors had a small negative effect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d99c750-5a21-48fe-9391-cd5b318ef4a5",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "\n",
    "Similar to Experiment 2, but in VSC test task, more than one example of the correct category was shown (redundancy). It had no effect.\n",
    "\n",
    "+ One failed explanation for unintuitive result: redundancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4471f2a-f22e-44a4-96c1-be616947527c",
   "metadata": {},
   "source": [
    "## General Discussion\n",
    "\n",
    "`5.1. Why is the visual-search categorization task so difficult?` - exactly\n",
    "\n",
    "1. Limited training with the categories\n",
    "2. CVM training schedule\n",
    "3. Verbal target cues\n",
    "\n",
    "### Theoretical Implication\n",
    "\n",
    "`the complex polygon stimuli were likely treated as II stimuli.`\n",
    "\n",
    "```\n",
    "Hence, future work should focus on adding\n",
    "perceptual noise and occlusion to explore how perceptual ambiguity\n",
    "interacts with display size and category structure.\n",
    "```\n",
    "+ I have not done this yet, but I could write image augmentation transforms to accomplish this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4199f527-b83a-4583-aff0-742dc36b114b",
   "metadata": {},
   "source": [
    "# Extra Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2743e9-3d10-4ef3-92a7-5ce881c712f6",
   "metadata": {},
   "source": [
    "Taking connectionism serioulsy means paying attention to the high dimensionality of input, intermediate representations, and output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79db2546-c574-41df-8635-62acbf0f0d68",
   "metadata": {},
   "source": [
    "I'm proposing a undetected confounding factor that could explain the anomalous result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54221524-fc7b-460f-aab1-3aa71aa200fb",
   "metadata": {},
   "source": [
    "Wondering, as Smith(2005) did, why humans are terrible at a synthetic visual categorization task is akin to wondering how humans are able to catch a baseball despite not being able to solve newtonian kinematics equations within a split second. Nevertheless, we are able to detect,categorize, and predict the trajectory of a fast moving ball. The explanatory neurobiological reality is that humans have excellent object classification ability thanks to a high-dimensional, complex environment, not in spite of it. In this article, I peer inside artificial neural networks to demonstrate that oversimplification of tasks is detrimental to the performance of densely-connected cognitive systems.\n",
    "\n",
    "Even MIT Integration Bee winners can't do it fast enough to be useful in catching a ball."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309ad7f-a9d7-428b-b22e-ad1fae1d068a",
   "metadata": {},
   "source": [
    "Feature pyramid networks (FPN) is a good example of a deep learning computer vision innovation that takes advantage of mutli-scale, multi-order information for higher accuracy in detection/classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6dc7fa-ee0f-41b3-a063-dc0b833938bb",
   "metadata": {},
   "source": [
    "Biological feasibility of artificial neural networks presented here are irrelevant to our discussion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f82441-8bc3-44a2-829a-218d89a19443",
   "metadata": {},
   "source": [
    "The general direction of my research is: The ability to read single-cell activations for neurons in our brain requires technology of the very distant future. However, the computational equivalent of it, reading the parameters of an artificial neural network, is available to us today. While parsing and interepreting the parameters in an ANN is not trivial (in fact, it is a field unto itself), I think this *in silico* approach has the potential to positively augment naturalistic cognitive science research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3078c05-6aed-4317-b3aa-3511df925854",
   "metadata": {},
   "source": [
    "(on linear net learning the left-most pattern that was created as a kind of dataset generation artifact)\n",
    "Furthermore, this result shows that today's industry best practices in ML (research and deployment) are insufficient to ensure that the model is learning something proper. Neural networks can learn anything, and often it learns things you don't want it to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6677cf9-680a-4e3a-a4a8-129cc02056dc",
   "metadata": {},
   "source": [
    "The model displayed random seed fragility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb1420f-fee6-4602-bb34-dad964bc00a4",
   "metadata": {},
   "source": [
    "Why does ANN work so well on MNIST? Because handwritten digits can be thought of as high-order fourtier transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcad18c-2b0c-454e-8794-b8c440601c6d",
   "metadata": {},
   "source": [
    "Imagenet is precisely a categorization task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ab9f8a-fe69-41fb-a439-2bbc0b2ca3fd",
   "metadata": {},
   "source": [
    "Convolutional networks demonstrate that multiple layers (types of filters) are utilized in categorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b14d318-b3f5-43a3-9347-07ac9eb80f2f",
   "metadata": {},
   "source": [
    "HDVSC - High Dimensionality Visual Search and Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465c74b-be37-4642-b756-b43fbe976e23",
   "metadata": {},
   "source": [
    "On uncomplex images, we cannot form robust, high-dimensional representations. That is why visual search fails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea8937-f3f0-49d7-b3bc-af5f116f41ad",
   "metadata": {},
   "source": [
    "The universal approximation theorem: Any neural network with at least a single hidden layer with sigmoid non-linearities is capable of approximating any continuous function. \n",
    "\n",
    "G.Cybenko, Approximation by superpositions of a sigmoidal function. 1989\n",
    "\n",
    "K. Hornik. Multiplayer Feedforward Networks Are Universal Approximators. 1989\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75932b4e-95f1-448d-93ca-de689455053f",
   "metadata": {},
   "source": [
    "Spiking neural networks are definitely exciting, but the difference between third generation spiking neural networks and current second generation neural networks are abstracted away in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b88441-b519-460f-887d-6065b1b0703d",
   "metadata": {},
   "source": [
    "If everything here is true, How are we to conduct controlled psychological research?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edaadd4-bc96-4557-be1b-c787c4b310e2",
   "metadata": {},
   "source": [
    "Beyond ML interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d69274e-4b02-485b-b74a-4fe231cba75f",
   "metadata": {},
   "source": [
    "Signals the possibility that a different paradigm might be needed to study visual search under ecological conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f9c3d3-6259-44fe-9887-d07cf51345d6",
   "metadata": {},
   "source": [
    "Deep learning researchers are largely uninterested because they're chasing SOTA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04beea01-1c84-4ee5-a85f-dc841b8d886d",
   "metadata": {},
   "source": [
    "# Testing my theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8085e1d1-a038-4992-925b-760c6a4f658f",
   "metadata": {},
   "source": [
    "I am fully seized of the difficulty of reproducibly generating a large enough set of images on which to test categorization tasks.\n",
    "\n",
    "The answer must be some sort where we define some parameters (seed), but the much larger number of other parameters are defined from a high-dimensional network. The first thing that comes to mind is Generative Adversarial networks (GANs). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99156d59-2193-4f5b-961f-395fadd3b129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f53877f7-8aa3-482d-b190-7eb874852044",
   "metadata": {},
   "source": [
    "# Key Jargon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ab9f2-11b9-4f66-8058-fb0d34ea00de",
   "metadata": {},
   "source": [
    "+ SKill transfer\n",
    "+ Verbalizable\n",
    "+ pre-decisional\n",
    "+ Same-different categorization (SDC) task\n",
    "+ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
