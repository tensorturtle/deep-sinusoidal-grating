{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2405089a-24bb-4c78-bc25-dd7fb63bc24f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Notes from \"Can categorical knowledge be used in visual search?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6242e7d-4ecf-436e-9ad1-197cd0504ca1",
   "metadata": {},
   "source": [
    "BE SURE TO SAY POSITIVE THINGS ABOUT REFERRED PAPERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1fc815-5926-465a-81ea-04515ba96c99",
   "metadata": {},
   "source": [
    "Story: I have developed AI vision systems that can detect and categorize objects from complex scenes in real time, and with an energy efficiency on par with the human brain. Based on my experiences, I feel that I have something to contribute to the discourse about human visual facilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c48ff-7d96-4584-a757-daed7d8a1cbe",
   "metadata": {},
   "source": [
    "Fun fact: I was probably one of the `Fifty-eight undergraduate students at Purdue University` who `were recruited to participate in Experiment 2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df3b57-6889-41a9-89cc-fd5e2b3eefaa",
   "metadata": {},
   "source": [
    "Abstract\n",
    "\n",
    "```\n",
    "However, Smith et al. only studied one kind of category structure.\n",
    "This article presents the results of three experiments exploring the effect of display size on perceptual cate-\n",
    "gorization as a function of category structure. We show that rule-based and information-integration categories\n",
    "are differently affected by display size in the visual search categorization task. \n",
    "```\n",
    "\n",
    "I think this paper heads in the right direction, but does not go nearly far enough to reap the benefits of added parameterization and complexity of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12379417-9f66-404a-a97b-33eb334c7ecc",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "\n",
    "`Categorization reduces the complexity of the environment.`\n",
    "\n",
    "'Complexity' being the key word here.\n",
    "\n",
    "We are assuming a high level of complexity for categorization to work. Generating synthetic environments/tasks that do not have *sufficient* complexity might be problematic.\n",
    "\n",
    "Before it gets reduced, it gets vastly expanded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd7b137-c00a-4eea-b141-181a5d032911",
   "metadata": {},
   "source": [
    "1.1 Visual search and categorization\n",
    "\n",
    "```\n",
    "the VSC task allows for studying how participants can parse a relatively complex scene in order to achieve a categorization decision\n",
    "```\n",
    "\n",
    "Is it complex enough? Perhaps not.\n",
    "\n",
    "Proposed reasons for counterintuitive results\n",
    "\n",
    "+ `Category representations learned during the category training portion of the VSC task were not sufficient to support visual search. Categorization and visual search are two different tasks, and Helie and colleagues have shown that ths structures of the learned categories affct the generality and transferability of the category representations.`\n",
    "\n",
    "`Helie and Ashby argued that learning different category structures leads to different kinds of category representations, and that different category representations allow for different generalizability and transfer performance`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98606a29-1490-48a8-a83b-42b341bbccec",
   "metadata": {},
   "source": [
    "Smith(2015)'s dot-distortion task is probablly a informaiton integration task. With sinusoidal gratings, it appears that people are better at generalizing / recalling rule-based schemes than information integration schemes.\n",
    "\n",
    "Had Smith(2015) tried using a rule-based dot-distortion, he might have had more success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4199f527-b83a-4583-aff0-742dc36b114b",
   "metadata": {},
   "source": [
    "# Extra Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2743e9-3d10-4ef3-92a7-5ce881c712f6",
   "metadata": {},
   "source": [
    "Taking connectionism serioulsy means paying attention to the high dimensionality of input, intermediate representations, and output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79db2546-c574-41df-8635-62acbf0f0d68",
   "metadata": {},
   "source": [
    "I'm proposing a undetected confounding factor that could explain the anomalous result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54221524-fc7b-460f-aab1-3aa71aa200fb",
   "metadata": {},
   "source": [
    "Wondering, as Smith(2005) did, why humans are terrible at a synthetic visual categorization task is akin to wondering how humans are able to catch a baseball despite not being able to solve newtonian kinematics equations within a split second. Nevertheless, we are able to detect,categorize, and predict the trajectory of a fast moving ball. The explanatory neurobiological reality is that humans have excellent object classification ability thanks to a high-dimensional, complex environment, not in spite of it. In this article, I peer inside artificial neural networks to demonstrate that oversimplification of tasks is detrimental to the performance of densely-connected cognitive systems.\n",
    "\n",
    "Even MIT Integration Bee winners can't do it fast enough to be useful in catching a ball."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309ad7f-a9d7-428b-b22e-ad1fae1d068a",
   "metadata": {},
   "source": [
    "Feature pyramid networks (FPN) is a good example of a deep learning computer vision innovation that takes advantage of mutli-scale, multi-order information for higher accuracy in detection/classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6dc7fa-ee0f-41b3-a063-dc0b833938bb",
   "metadata": {},
   "source": [
    "Biological feasibility of artificial neural networks presented here are irrelevant to our discussion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04beea01-1c84-4ee5-a85f-dc841b8d886d",
   "metadata": {},
   "source": [
    "# Testing my theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8085e1d1-a038-4992-925b-760c6a4f658f",
   "metadata": {},
   "source": [
    "I am fully seized of the difficulty of reproducibly generating a large enough set of images on which to test categorization tasks.\n",
    "\n",
    "The answer must be some sort where we define some parameters (seed), but the much larger number of other parameters are defined from a high-dimensional network. The first thing that comes to mind is Generative Adversarial networks (GANs). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07dbf9-e42e-4f71-b58e-7998290de7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
